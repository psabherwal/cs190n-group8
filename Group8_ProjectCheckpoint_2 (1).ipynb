{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e35778",
   "metadata": {},
   "source": [
    "# Term Project: Checkpoint #2\n",
    "\n",
    "**Group 8:** Palvi Sabherwal, Hannah Shakouri, Emily Thai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636d487",
   "metadata": {},
   "source": [
    "## EXPERIMENT\n",
    "\n",
    "*Provide a high-level explanation of the experiment(s) that you want to run through netUnicorn/netReplica. What type of data do you need to collect?*\n",
    "\n",
    "Our projectâ€™s goal is to predict download times of video chunks on video streaming platforms to minimize the interruptions caused by fluctuations in network performance. The input of our model will be historic QoS metrics, including throughput, latency, and packet loss. As for the training data we plan on running through netUnicorn/netReplica, we will collect time-series data on historical QoS metrics for video streaming sessions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1159a54",
   "metadata": {},
   "source": [
    "## DATA COLLECTION PIPELINES\n",
    "*Provide (pseudo)code for the pipeline(s) that you will run for your data collection.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5b7b1",
   "metadata": {},
   "source": [
    "### Import Statements\n",
    "*For each task in your pipeline, provide a reference to the implementation of this task that you will use for your data collection.*\n",
    "\n",
    "These imports statements are our reference to the implementations used in our pipeline tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86096cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from netunicorn.client.remote import RemoteClient, RemoteClientException\n",
    "from netunicorn.base import Experiment, ExperimentStatus, Pipeline\n",
    "from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture\n",
    "from netunicorn.library.tasks.upload.fileio import UploadToFileIO\n",
    "from netunicorn.library.tasks.upload.webdav import UploadToWebDav\n",
    "from netunicorn.library.tasks.basic import SleepTask\n",
    "from netunicorn.library.tasks.measurements.ookla_speedtest import SpeedTest\n",
    "from netunicorn.library.tasks.video_watchers.youtube_watcher import WatchYouTubeVideo\n",
    "from netunicorn.library.tasks.video_watchers.vimeo_watcher import WatchVimeoVideo\n",
    "from netunicorn.library.tasks.video_watchers.twitch_watcher import WatchTwitchStream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141631b",
   "metadata": {},
   "source": [
    "### Set Up netUnicorn\n",
    "Choosing a device for our project. Using our group's netUnicorn API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a050292",
   "metadata": {},
   "outputs": [],
   "source": [
    "NETUNICORN_ENDPOINT = os.environ.get('NETUNICORN_ENDPOINT', 'https://pinot.cs.ucsb.edu/netunicorn')\n",
    "NETUNICORN_LOGIN = os.environ.get('NETUNICORN_LOGIN', 'cs190n8')       \n",
    "NETUNICORN_PASSWORD = os.environ.get('NETUNICORN_PASSWORD', 'kfazTdrx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f860b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check: True\n",
      "[[snl-server-5], <Uncountable node pool with next node template: [aws-fargate-A-cs190n8-, aws-fargate-B-cs190n8-, aws-fargate-ARM64-cs190n8-]>]\n"
     ]
    }
   ],
   "source": [
    "client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "print(\"Health Check: {}\".format(client.healthcheck()))\n",
    "nodes = client.get_nodes()\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebb85fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_node = 'snl-server-5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b34d87",
   "metadata": {},
   "source": [
    "### Collecting Network Data for Video Streaming\n",
    "In our collecting network data pipeline we will be collecting packet captures while streaming video for YouTube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b0d6f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:executor_local:Parsed configuration: Gateway located on fake\n",
      "INFO:executor_local:Current directory: /home/psabherwal/cs190n-fall-2024/project\n"
     ]
    }
   ],
   "source": [
    "from netunicorn.executor import get_local_executor\n",
    "executor = get_local_executor(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38ac9228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(3efd2398-1da5-4705-925e-1a42205c17ea): {'root': [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24f9a0>], 1: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f730>], 2: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f640>], 3: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f610>], 4: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f5b0>], 5: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f550>], 6: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24f670>], 7: [<netunicorn.library.tasks.basic.SleepTask with name 5fff0e6f-adde-4d33-ac22-62a71b7efe30>], 8: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24f700>], 9: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24edd0>], 10: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24eec0>], 11: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24eef0>], 12: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24ef50>], 13: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24efb0>], 14: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24ee90>], 15: [<netunicorn.library.tasks.basic.SleepTask with name bc876c76-5a1a-47d2-81c5-afec553a79de>], 16: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24ee00>], 17: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f190>], 18: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f280>], 19: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f2b0>], 20: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f310>], 21: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24f370>], 22: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24f250>], 23: [<netunicorn.library.tasks.basic.SleepTask with name 7ac4d98a-85f6-4343-849a-d546f07be046>], 24: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24f1c0>], 25: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24fbe0>], 26: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24fcd0>], 27: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24fd00>], 28: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24fd60>], 29: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24fdc0>], 30: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24fca0>], 31: [<netunicorn.library.tasks.basic.SleepTask with name a1c721f2-60a0-4dc9-8060-e1fb38daabcd>], 32: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24fc10>], 33: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24ffa0>], 34: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24d150>], 35: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24d120>], 36: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24d0c0>], 37: [<netunicorn.library.tasks.video_watchers.youtube_watcher.WatchYouTubeVideo object at 0x7fcf8a24d060>], 38: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24d180>]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "\n",
    "# Flag to enable early stopping -- so if any task fails pipeline would go on working\n",
    "# pipeline.early_stopping = False\n",
    "\n",
    "# Generate Data for YouTube\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/youtube_1min.pcap\", name=\"1min_captureYT\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=0g1Q4fBDp2U&pp=ygUMMSBtaW4gdmlkZW9z\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"1min_captureYT\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/youtube_2min.pcap\", name=\"2min_captureYT\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=0CmtDk-joT4&ab_channel=Koi\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"2min_captureYT\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/youtube_5min.pcap\", name=\"5min_captureYT\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=6-2ra25RVRs&pp=ygUMNSBtaW4gdmlkZW9z\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"5min_captureYT\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/youtube_10min.pcap\", name=\"10min_captureYT\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=vCkhJeom7zU&pp=ygUNMTAgbWluIHZpZGVvcw%3D%3D\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"10min_captureYT\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/youtube_15min.pcap\", name=\"15min_captureYT\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=co47u19cbds&pp=ygUNMTUgbWluIHZpZGVvcw%3D%3D\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"15min_captureYT\"))\n",
    "\n",
    "# pipeline.then(UploadToWebDav(filepaths={\"/tmp/youtube_1min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/youtube_capture\", username=\"test\", password=\"test\"))\n",
    "# pipeline.then(UploadToWebDav(filepaths={\"/tmp/youtube_2min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/youtube_capture\", username=\"test\", password=\"test\"))\n",
    "# pipeline.then(UploadToWebDav(filepaths={\"/tmp/youtube_5min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/youtube_capture\", username=\"test\", password=\"test\"))\n",
    "# pipeline.then(UploadToWebDav(filepaths={\"/tmp/youtube_10min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/youtube_capture\", username=\"test\", password=\"test\"))\n",
    "# pipeline.then(UploadToWebDav(filepaths={\"/tmp/youtube_15min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/youtube_capture\", username=\"test\", password=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0894755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:executor_local:asyncio.run() cannot be called from a running event loop\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/netunicorn/netunicorn-executor/src/netunicorn/executor/executor.py\", line 134, in __call__\n",
      "    asyncio.run(self.execute())\n",
      "  File \"/usr/lib/python3.10/asyncio/runners.py\", line 33, in run\n",
      "    raise RuntimeError(\n",
      "RuntimeError: asyncio.run() cannot be called from a running event loop\n",
      "CRITICAL:executor_local:Failed to execute the graph. Shutting down.\n",
      "INFO:executor_local:Skipping reporting results due to execution graph setting.\n"
     ]
    }
   ],
   "source": [
    "executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c9131a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(2e55f1be-6e0a-4520-bd8e-6129df6bb187): {'root': [<netunicorn.library.tasks.basic.SleepTask with name 729d6002-4479-4e3c-be01-a8111592331c>], 1: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a20add0>], 2: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a20a4a0>], 3: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a20a560>], 4: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a209840>], 5: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a209bd0>], 6: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a208d60>], 7: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a20ada0>], 8: [<netunicorn.library.tasks.basic.SleepTask with name f0f45126-efc2-4d20-a5cd-7904ebfe23b2>], 9: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a20a5c0>], 10: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a20b850>], 11: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a209ed0>], 12: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a20b4c0>], 13: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a20ad70>], 14: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24e7d0>], 15: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a20b3d0>], 16: [<netunicorn.library.tasks.basic.SleepTask with name f4a0d13f-ea7f-44ea-bf06-8690f8b0f38c>], 17: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24cbb0>], 18: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24c490>], 19: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24d4e0>], 20: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24d600>], 21: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24d630>], 22: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24d720>], 23: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24d4b0>], 24: [<netunicorn.library.tasks.basic.SleepTask with name 6d6b245b-3eb4-4340-adbd-ba72fa38997c>], 25: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24c7c0>], 26: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24e680>], 27: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24e740>], 28: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24eb30>], 29: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24c310>], 30: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24c430>], 31: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24e650>], 32: [<netunicorn.library.tasks.basic.SleepTask with name 8416bf40-d465-49b4-898d-8c3509d3106a>], 33: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24e6e0>], 34: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24d390>], 35: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24dc00>], 36: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24dab0>], 37: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24dba0>], 38: [<netunicorn.library.tasks.video_watchers.vimeo_watcher.WatchVimeoVideo object at 0x7fcf8a24db70>], 39: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24da80>]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "# Flag to enable early stopping -- so if any task fails pipeline would go on working\n",
    "# pipeline.early_stopping = False\n",
    "\n",
    "# Generate Data for Vimeo\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/vimeo_1min.pcap\", name=\"1min_captureVM\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchVimeoVideo(\"https://vimeo.com/820625227?autoplay=1\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"1min_captureVM\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/vimeo_2min.pcap\", name=\"2min_captureVM\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchVimeoVideo(\"https://vimeo.com/867196026\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"2min_captureVM\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/vimeo_5min.pcap\", name=\"5min_captureVM\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchVimeoVideo(\"https://vimeo.com/391703912\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"5min_captureVM\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/vimeo_10min.pcap\", name=\"10min_captureVM\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchVimeoVideo(\"https://vimeo.com/675873896\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"10min_captureVM\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/vimeo_15min.pcap\", name=\"15min_captureVM\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchVimeoVideo(\"https://vimeo.com/1031379349\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"15min_captureVM\"))\n",
    "\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/vimeo_1min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/vimeo_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/vimeo_2min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/vimeo_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/vimeo_5min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/vimeo_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/vimeo_10min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/vimeo_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/vimeo_15min.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/vimeo_capture\", username=\"test\", password=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b40976d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(cdec3207-a8a9-4c7e-b296-ab5d5a3e8039): {'root': [<netunicorn.library.tasks.basic.SleepTask with name 39b551b4-a0a3-4e33-ac94-f9f4474fda21>], 1: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a20ab00>], 2: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a2099c0>], 3: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a20a590>], 4: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a20a170>], 5: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24d930>], 6: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24d900>], 7: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a20bfd0>], 8: [<netunicorn.library.tasks.basic.SleepTask with name f8d02915-20bf-4887-9405-c1ebf1a80d93>], 9: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24d840>], 10: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24ec50>], 11: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24d000>], 12: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24f9d0>], 13: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24ce20>], 14: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24cd30>], 15: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24ff10>], 16: [<netunicorn.library.tasks.basic.SleepTask with name 7dbe63cb-ac01-472b-bfd3-e115eccec113>], 17: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a24ec80>], 18: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24ece0>], 19: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24ceb0>], 20: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a24c520>], 21: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a354250>], 22: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a357a30>], 23: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a24c070>], 24: [<netunicorn.library.tasks.basic.SleepTask with name 4ef1be7a-bd4a-46e2-9433-b893e82207e7>], 25: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a357850>], 26: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a354220>], 27: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a3573a0>], 28: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a356f50>], 29: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a357b50>], 30: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a356dd0>], 31: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a357640>], 32: [<netunicorn.library.tasks.basic.SleepTask with name caaa0987-dfc3-432e-aec5-202f60f0a0fd>], 33: [<netunicorn.library.tasks.capture.tcpdump.StartCapture object at 0x7fcf8a357a00>], 34: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a357310>], 35: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a354190>], 36: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a354550>], 37: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a1fe140>], 38: [<netunicorn.library.tasks.video_watchers.twitch_watcher.WatchTwitchStream object at 0x7fcf8a1fc460>], 39: [<netunicorn.library.tasks.capture.tcpdump.StopNamedCapture object at 0x7fcf8a356a10>]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "# Flag to enable early stopping -- so if any task fails pipeline would go on working\n",
    "# pipeline.early_stopping = False\n",
    "\n",
    "# Generate Data for Twitch\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/twitch_capture1.pcap\", name=\"1_captureTW\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchTwitchStream(\"https://www.twitch.tv/emilycc/clip/BoringGloriousGoblinOMGScoots-HzN323BdbgWMC8z2\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"1_captureTW\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/twitch_capture2.pcap\", name=\"2_captureTW\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchTwitchStream(\"https://www.twitch.tv/chess24/clip/EvilHedonisticLadiesDBstyle-Qvx2Iv5rD18TBkMc\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"2_captureTW\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/twitch_capture3.pcap\", name=\"3_captureTW\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchTwitchStream(\"https://www.twitch.tv/dinabelenkaya/clip/BlueArtisticLarkDendiFace-6GsaEv3Rt8vpRoTL\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"3_captureTW\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/twitch_capture4.pcap\", name=\"4_captureTW\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchTwitchStream(\"https://www.twitch.tv/chess24/clip/PlayfulEndearingOpossumPeoplesChamp-d1sejwuAMspNlEz7\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"4_captureTW\"))\n",
    "\n",
    "pipeline.then(SleepTask(2))\n",
    "\n",
    "pipeline.then(StartCapture(filepath=\"/tmp/twitch_capture5.pcap\", name=\"5_captureTW\"))\n",
    "for _ in range(5):\n",
    "    pipeline.then(WatchTwitchStream(\"\", 10))\n",
    "pipeline.then(StopNamedCapture(start_capture_task_name=\"5_captureTW\"))\n",
    "\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/twitch_capture1.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/twitch_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/twitch_capture2.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/twitch_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/twitch_capture3.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/twitch_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/twitch_capture4.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/twitch_capture\", username=\"test\", password=\"test\"))\n",
    "#pipeline.then(UploadToWebDav(filepaths={\"/tmp/twitch_capture5.pcap\"}, endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n8/twitch_capture\", username=\"test\", password=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1040e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check: True\n",
      "[[snl-server-5], <Uncountable node pool with next node template: [aws-fargate-A-cs190n8-, aws-fargate-B-cs190n8-, aws-fargate-ARM64-cs190n8-]>]\n"
     ]
    }
   ],
   "source": [
    "client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "print(\"Health Check: {}\".format(client.healthcheck()))\n",
    "nodes = client.get_nodes()\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "138d51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Deployment: Node=snl-server-5, executor_id=, prepared=False, error=None\n"
     ]
    }
   ],
   "source": [
    "working_nodes = nodes.filter(lambda node: node.name.startswith(working_node)).take(1)\n",
    "\n",
    "# Creating the experiment\n",
    "experiment = Experiment().map(pipeline, working_nodes)\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6675d33",
   "metadata": {},
   "source": [
    "### Preparing the Experiment\n",
    "We will use a predefined DockerImage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ad1d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netunicorn.base import DockerImage\n",
    "for deployment in experiment:\n",
    "    # you can explore the image on the DockerHub\n",
    "    deployment.environment_definition = DockerImage(image='speeeday/chromium-speedtest:0.3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87b2f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = \"datacoll\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc693e",
   "metadata": {},
   "source": [
    "Now we can prepare the experiment, check for any errors and execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a23eab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.READY\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.delete_experiment(experiment_label)\n",
    "except RemoteClientException:\n",
    "    pass\n",
    "\n",
    "client.prepare_experiment(experiment, experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status == ExperimentStatus.READY:\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd2fb40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared: True, error: None\n"
     ]
    }
   ],
   "source": [
    "for deployment in client.get_experiment_status(experiment_label).experiment:\n",
    "    print(f\"Prepared: {deployment.prepared}, error: {deployment.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b593b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.FINISHED\n"
     ]
    }
   ],
   "source": [
    "client.start_execution(experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status != ExperimentStatus.RUNNING:\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c153d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node name: snl-server-5\n",
      "Error: Executor timed out\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8120/748353929.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {report.error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m  \u001b[0;31m# report stores results of execution and corresponding log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# result is a returns.result.Result object, could be Success of Failure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from returns.pipeline import is_successful\n",
    "\n",
    "for report in info.execution_result:\n",
    "    print(f\"Node name: {report.node.name}\")\n",
    "    print(f\"Error: {report.error}\")\n",
    "\n",
    "    result, log = report.result  # report stores results of execution and corresponding log\n",
    "    \n",
    "    # result is a returns.result.Result object, could be Success of Failure\n",
    "    print(f\"Result is: {type(result)}\")\n",
    "    data = result.unwrap() if is_successful(result) else result.failure()\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # we also can explore logs\n",
    "    for line in log:\n",
    "        print(line.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95159e9",
   "metadata": {},
   "source": [
    "## DATA COLLECTION UPDATE\n",
    "*Provide an update on the status of your data collection. Have you been able to successfully collect and label a packet trace collected through netunicorn for your project? If yes, how many traces have you collected? Do you plan to scale up your data collection any further?*\n",
    "\n",
    "Currently, we have collected the data of five videos from each platform: YouTube, Vimeo, and Twitch. For YouTube and Vimeo, each video has a different duration (1 min, 2 min, 5 min, 10 min, and 15 min). For Twitch, each video is around 1 minute long. In total, we have collected 15 packet traces (.pcap files). Bellow we have labeled the packet traces we have collected so far. We are considering expanding our data collection (by 1-2 videos) for each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682cf746",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/md0/cs190n-test/youtube_video_capture_ISCX.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4170512/3454718174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_youtube\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/md0/cs190n-test/youtube_video_capture_ISCX.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_vimeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/md0/cs190n-test/vimeo_video_capture_ISCX.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_twitch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/md0/cs190n/cs190n8/twitch_stream_capture_ISCX.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_youtube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/md0/cs190n-test/youtube_video_capture_ISCX.csv'"
     ]
    }
   ],
   "source": [
    "df_youtube1 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/youtube_1min_capture_ISCX.csv\")\n",
    "df_youtube2 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/youtube_2min_capture_ISCX.csv\")\n",
    "df_youtube5 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/youtube_5min_capture_ISCX.csv\")\n",
    "df_youtube10 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/youtube_10min_capture_ISCX.csv\")\n",
    "df_youtube15 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/youtube_15min_capture_ISCX.csv\")\n",
    "#df_youtube = pd.concat([df_youtube1, df_youtube2, df_youtube5, df_youtube10, df_youtube15], axis=1)\n",
    "\n",
    "df_vimeo1 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/vimeo_1min_capture_ISCX.csv\")\n",
    "df_vimeo2 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/vimeo_2min_capture_ISCX.csv\")\n",
    "df_vimeo5 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/vimeo_5min_capture_ISCX.csv\")\n",
    "df_vimeo10 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/vimeo_10min_capture_ISCX.csv\")\n",
    "df_vimeo15 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/vimeo_15min_capture_ISCX.csv\")\n",
    "#df_vimeo = pd.concat([df_vimeo1, df_vimeo2, df_vimeo5, df_vimeo10, df_vimeo15], axis=1)\n",
    "\n",
    "df_twitch1 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/twitch_capture1_ISCX.csv\")\n",
    "df_twitch2 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/twitch_capture2_ISCX.csv\")\n",
    "df_twitch3 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/twitch_capture3_ISCX.csv\")\n",
    "df_twitch4 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/twitch_capture4_ISCX.csv\")\n",
    "df_twitch5 = pd.read_csv(\"/mnt/md0/cs190n/cs190n8/twitch_capture5_ISCX.csv\")\n",
    "#df_twitch = pd.concat([df_twitch1, df_twitch2, df_twitch3, df_twitch4, df_twitch5], axis=1)\n",
    "\n",
    "#print(df_youtube.columns)\n",
    "#print(df_vimeo.columns)\n",
    "#print(df_twitch.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DURATION = 180180\n",
    "PKT_BYTES = 1500\n",
    "MILLION = 1000000\n",
    "PAST_CHUNKS = 8\n",
    "FUTURE_CHUNKS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_data(video_sent_path, video_acked_path, time_start=None, time_end=None):\n",
    "    \"\"\"\n",
    "    Load data from files and calculate chunk transmission times.\n",
    "    \"\"\"\n",
    "    video_sent_df = pd.read_csv(video_sent_path)\n",
    "    video_acked_df = pd.read_csv(video_acked_path)\n",
    "\n",
    "    # Rename \"time (ns GMT)\" to \"time\" for convenience\n",
    "    video_sent_df.rename(columns={'time (ns GMT)': 'time'}, inplace=True)\n",
    "    video_acked_df.rename(columns={'time (ns GMT)': 'time'}, inplace=True)\n",
    "\n",
    "    # Convert nanosecond timestamps to datetime\n",
    "    video_sent_df['time'] = pd.to_datetime(video_sent_df['time'], unit='ns')\n",
    "    video_acked_df['time'] = pd.to_datetime(video_acked_df['time'], unit='ns')\n",
    "\n",
    "    # Filter by time range\n",
    "    if time_start:\n",
    "        time_start = pd.to_datetime(time_start)\n",
    "        video_sent_df = video_sent_df[video_sent_df['time'] >= time_start]\n",
    "        video_acked_df = video_acked_df[video_acked_df['time'] >= time_start]\n",
    "    if time_end:\n",
    "        time_end = pd.to_datetime(time_end)\n",
    "        video_sent_df = video_sent_df[video_sent_df['time'] <= time_end]\n",
    "        video_acked_df = video_acked_df[video_acked_df['time'] <= time_end]\n",
    "\n",
    "    # Process the data\n",
    "    return calculate_trans_times(video_sent_df, video_acked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52749a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trans_times(video_sent_df, video_acked_df):\n",
    "    \"\"\"\n",
    "    Calculate transmission times from video_sent and video_acked datasets using session_id.\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    last_video_ts = {}\n",
    "\n",
    "    for _, row in video_sent_df.iterrows():\n",
    "        session = row['session_id']  # Use only session_id to track sessions\n",
    "        if session not in d:\n",
    "            d[session] = {}\n",
    "            last_video_ts[session] = None\n",
    "\n",
    "        video_ts = int(row['video_ts'])\n",
    "        if last_video_ts[session] is not None:\n",
    "            if video_ts != last_video_ts[session] + VIDEO_DURATION:\n",
    "                continue\n",
    "\n",
    "        last_video_ts[session] = video_ts\n",
    "        d[session][video_ts] = {\n",
    "            'sent_ts': pd.Timestamp(row['time']),\n",
    "            'size': float(row['size']) / PKT_BYTES,\n",
    "            'delivery_rate': float(row['delivery_rate']) / PKT_BYTES,\n",
    "            'cwnd': float(row['cwnd']),\n",
    "            'in_flight': float(row['in_flight']),\n",
    "            'min_rtt': float(row['min_rtt']) / MILLION,\n",
    "            'rtt': float(row['rtt']) / MILLION,\n",
    "        }\n",
    "\n",
    "    for _, row in video_acked_df.iterrows():\n",
    "        session = row['session_id']  # Use only session_id\n",
    "        if session not in d:\n",
    "            continue\n",
    "\n",
    "        video_ts = int(row['video_ts'])\n",
    "        if video_ts not in d[session]:\n",
    "            continue\n",
    "\n",
    "        dsv = d[session][video_ts]\n",
    "        sent_ts = dsv['sent_ts']\n",
    "        acked_ts = pd.Timestamp(row['time'])\n",
    "        dsv['acked_ts'] = acked_ts\n",
    "        dsv['trans_time'] = (acked_ts - sent_ts).total_seconds()\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_raw_data(\"/mnt/md0/cs190n/video_sent.csv\", \"/mnt/md0/cs190n/video_acked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_past_chunks(ds, next_ts, row):\n",
    "    i = 1\n",
    "    past_chunks = []\n",
    "    while i <= PAST_CHUNKS:\n",
    "        ts = next_ts - i * VIDEO_DURATION\n",
    "        if ts in ds and 'trans_time' in ds[ts]:\n",
    "            past_chunks = [ds[ts]['delivery_rate'],\n",
    "                           ds[ts]['cwnd'], ds[ts]['in_flight'],\n",
    "                           ds[ts]['min_rtt'], ds[ts]['rtt'],\n",
    "                           ds[ts]['size'], ds[ts]['trans_time']] + past_chunks\n",
    "        else:\n",
    "            nts = ts + VIDEO_DURATION  # padding with the nearest ts\n",
    "            padding = [ds[nts]['delivery_rate'],\n",
    "                       ds[nts]['cwnd'], ds[nts]['in_flight'],\n",
    "                       ds[nts]['min_rtt'], ds[nts]['rtt']]\n",
    "            if nts == next_ts:\n",
    "                padding += [0, 0]  # next_ts is the first chunk to send\n",
    "            else:\n",
    "                padding += [ds[nts]['size'], ds[nts]['trans_time']]\n",
    "            break\n",
    "        i += 1\n",
    "    if i != PAST_CHUNKS + 1:  # break in the middle; padding must exist\n",
    "        while i <= PAST_CHUNKS:\n",
    "            past_chunks = padding + past_chunks\n",
    "            i += 1\n",
    "    row += past_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_output(d):\n",
    "    ret = [{'in': [], 'out': []} for _ in range(5)]  # FUTURE_CHUNKS = 5\n",
    "\n",
    "    for session in d:\n",
    "        ds = d[session]\n",
    "\n",
    "        for next_ts in ds:\n",
    "            if 'trans_time' not in ds[next_ts]:\n",
    "                continue\n",
    "\n",
    "            row = []\n",
    "\n",
    "            # Append past chunks\n",
    "            append_past_chunks(ds, next_ts, row)\n",
    "\n",
    "            # Append the TCP info of the next chunk\n",
    "            row += [ds[next_ts]['delivery_rate'],\n",
    "                    ds[next_ts]['cwnd'], ds[next_ts]['in_flight'],\n",
    "                    ds[next_ts]['min_rtt'], ds[next_ts]['rtt']]\n",
    "\n",
    "            # Generate FUTURE_CHUNKS rows\n",
    "            for i in range(5):  # FUTURE_CHUNKS = 5\n",
    "                row_i = row.copy()\n",
    "\n",
    "                ts = next_ts + i * VIDEO_DURATION\n",
    "                if ts in ds and 'trans_time' in ds[ts]:\n",
    "                    row_i += [ds[ts]['size']]\n",
    "\n",
    "                    ret[i]['in'].append(row_i)\n",
    "                    ret[i]['out'].append(ds[ts]['trans_time'])\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667864a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(output_file, processed_data):\n",
    "    \"\"\"\n",
    "    Save processed data to a file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(processed_data, f)\n",
    "    print(f\"Processed data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    DEFAULT_VIDEO_SENT_PATH = '/mnt/md0/cs190n/video_sent.csv'\n",
    "    DEFAULT_VIDEO_ACKED_PATH = '/mnt/md0/cs190n/video_acked.csv'\n",
    "    DEFAULT_OUTPUT_FILE = '/home/satyandra/output.pkl'\n",
    "    \n",
    "    #Latest datasets can be found at https://puffer.stanford.edu/results/\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Process video streaming datasets.\")\n",
    "    parser.add_argument('--video_sent_path', type=str, help='Path to the video_sent dataset CSV file.')\n",
    "    parser.add_argument('--video_acked_path', type=str, help='Path to the video_acked dataset CSV file.')\n",
    "    parser.add_argument('--output_file', type=str, help='Path to save the processed data.')\n",
    "    parser.add_argument('--time_start', type=str, default=None, help='Start time for filtering data (RFC3339 format).')\n",
    "    parser.add_argument('--time_end', type=str, default=None, help='End time for filtering data (RFC3339 format).')\n",
    "    #args = parser.parse_args()\n",
    "    #processed_data = prepare_input_output(prepare_raw_data(args.video_sent_path, args.video_acked_path,\n",
    "    #    time_start=args.time_start, time_end=args.time_end))\n",
    "    # save_processed_data(args.output_file, processed_data)\n",
    "    processed_data = prepare_input_output(prepare_raw_data(DEFAULT_VIDEO_SENT_PATH, DEFAULT_VIDEO_ACKED_PATH,\n",
    "        time_start=None, time_end=None))\n",
    "    save_processed_data(DEFAULT_OUTPUT_FILE, processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ee2ce",
   "metadata": {},
   "source": [
    "## Packet Trace Features\n",
    "*Provide a list of features that you will extract from the packet traces for your model.*\n",
    "\n",
    "Bellow are the features we will extract from our packet traces for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25481b",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "*Please provide a high-level explanation of the model type that you plan to train / evaluate. Provide a link to the python sci-kit implementation that you plan to use.*\n",
    "\n",
    "We plan on using the **RandomForestClassifier** to train and evaluate our data collection. The **RandomForestClassifier** is suitable for our project because it can handle high-dimensional data, such as packet trace features, and provides a measure of feature importance. This can be useful in understanding the significance of different features in classifying network traffic.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3368f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/psabherwal/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/psabherwal/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/psabherwal/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8add01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data frame to features and answers\n",
    "target_variable = 'Label'\n",
    "train_features = list(set(df.columns) - {target_variable})\n",
    "x_train = df[train_features]\n",
    "y_train = df[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78538b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and start training a classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_train.values)\n",
    "print(metrics.classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751411fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is your pandas DataFrame with 6 feature columns and a label column\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=[\"Label\"]).values  # Replace 'label' with the name of your label column\n",
    "y = df[\"Label\"].values\n",
    "\n",
    "# Encode labels (Vimeo, Twitch, Others) to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Define the neural network classifier\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 64)  # Input layer (6 features)\n",
    "        self.fc2 = nn.Linear(64, 32)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(32, 3)  # Output layer (3 classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / len(y_test)\n",
    "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
